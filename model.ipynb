{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics = [\n",
    "    'P07', 'P10', 'P11', 'P13', 'P14', 'P16', 'P17', 'P18', 'P22', 'P23', \n",
    "    'P24', 'P25', 'P26', 'P27', 'P28', 'P29', 'P30', 'P31', 'P32', 'P33', \n",
    "    'P34', 'P35', 'P36'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2a: Load LSL Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(362, 3)\n",
      "       time  onset  code\n",
      "0  16:54:02   1583    30\n",
      "1  16:54:16   1638    40\n",
      "2  16:54:26   1675    90\n",
      "3  16:54:35   1709    20\n",
      "4  16:54:48   1757    50\n"
     ]
    }
   ],
   "source": [
    "timings = []\n",
    "for subject in demographics:\n",
    "    path = os.path.join(\"data\", \"lsl\", subject+\"_lsl.tri\")\n",
    "    timing = pd.read_csv(path, sep=\";\", header=None, names=['time', 'onset', 'code'])\n",
    "    timing['time'] = pd.to_datetime(timing['time']).dt.strftime('%H:%M:%S')\n",
    "    timings.append(timing)\n",
    "print(timings[0].shape)\n",
    "print(timings[0].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2b: Load fNIRS Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Ch1       Ch2       Ch3       Ch4       Ch5       Ch6       Ch7  \\\n",
      "0 -0.344265  1.300073  1.832774 -0.887930 -0.207624  1.054426  1.424040   \n",
      "1 -0.043563  2.562058 -0.167581  2.891486 -0.264353  1.683089  1.235679   \n",
      "2  2.162913 -0.264095 -0.396215  1.580901  0.002871  1.394116  0.123256   \n",
      "3  0.851153  2.043946 -0.677578  2.979124  1.307757 -1.076036 -0.109632   \n",
      "4  0.285941  1.579658 -0.029958  1.671413  1.027549 -1.233513 -0.383056   \n",
      "\n",
      "        Ch8       Ch9      Ch10  ...     Ch169     Ch170     Ch171     Ch172  \\\n",
      "0  0.198594  1.644049 -0.490279  ... -0.803572  0.308469  0.180514 -0.080661   \n",
      "1  0.530382  1.011504 -0.394615  ... -1.591845 -0.604185 -0.723011 -0.758347   \n",
      "2 -0.103417  0.173477 -0.369911  ... -1.599090 -1.084251 -1.313623 -1.186320   \n",
      "3 -0.583261  0.361621 -0.536389  ... -1.597565 -1.118971 -1.539979 -1.409398   \n",
      "4 -0.818783  0.331133 -0.566345  ... -1.320694 -1.061013 -1.627339 -1.484535   \n",
      "\n",
      "      Ch173     Ch174     Ch175     Ch176     Ch177     Ch178  \n",
      "0 -0.672516  0.297929 -0.517992  1.065911  0.205167  0.420289  \n",
      "1 -1.381959  0.069620 -0.101927  0.218415  0.544626 -0.791255  \n",
      "2 -1.284653 -0.268327  0.408554 -0.628913  0.166033 -0.785242  \n",
      "3 -1.260107 -0.424392  0.390178 -0.154077 -0.079960 -0.523580  \n",
      "4 -1.212360 -0.534031  0.212474  0.237017 -0.556022  0.068713  \n",
      "\n",
      "[5 rows x 178 columns]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "data = {}\n",
    "for subject in demographics:\n",
    "    path = os.path.join(\"data\", \"data_csvs\", subject+\".csv\")\n",
    "    fnir = pd.read_csv(path, sep=\",\", header=0)\n",
    "    fnir = fnir.drop(columns=['Time'])\n",
    "    # standardize the data by channel\n",
    "    fnir = fnir.apply(zscore)\n",
    "    \n",
    "\n",
    "    data[subject] = fnir\n",
    "print(data['P07'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter channels to hbr and remove short separation channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>detector</th>\n",
       "      <th>type</th>\n",
       "      <th>channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>'hbr'</td>\n",
       "      <td>Ch2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>'hbr'</td>\n",
       "      <td>Ch4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>'hbr'</td>\n",
       "      <td>Ch6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>'hbr'</td>\n",
       "      <td>Ch8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>'hbr'</td>\n",
       "      <td>Ch10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source  detector   type channel\n",
       "0       1         2  'hbr'     Ch2\n",
       "1       1         3  'hbr'     Ch4\n",
       "2       1         5  'hbr'     Ch6\n",
       "3       1        17  'hbr'     Ch8\n",
       "4       2         1  'hbr'    Ch10"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the channel info\n",
    "channel_info = pd.read_csv(\"data/channel_info.csv\", sep=\",\", header=0)\n",
    "# filter for the hbr channels\n",
    "hbr = channel_info[channel_info['type'] == \"'hbr'\"]\n",
    "\n",
    "# drop short separation channels (anything above 28 will definitely be a short separation channel)\n",
    "hbr = hbr[hbr['detector'] < 29]\n",
    "hbr = hbr.reset_index(drop=True)\n",
    "hbr.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Ch2       Ch4       Ch6       Ch8      Ch10      Ch12      Ch14  \\\n",
      "0  1.300073 -0.887930  1.054426  0.198594 -0.490279  1.239808  1.022827   \n",
      "1  2.562058  2.891486  1.683089  0.530382 -0.394615  2.521916  1.168643   \n",
      "2 -0.264095  1.580901  1.394116 -0.103417 -0.369911  0.449242 -0.203777   \n",
      "3  2.043946  2.979124 -1.076036 -0.583261 -0.536389 -0.368066 -0.532009   \n",
      "4  1.579658  1.671413 -1.233513 -0.818783 -0.566345 -0.774057 -0.999820   \n",
      "\n",
      "       Ch16      Ch18      Ch20  ...     Ch144     Ch146     Ch148     Ch150  \\\n",
      "0 -0.598151 -1.566220 -0.636939  ...  1.713459 -0.221721  0.479469  0.172284   \n",
      "1 -0.649866 -1.349247 -1.578352  ...  4.528635 -0.579591 -0.131661 -0.245968   \n",
      "2 -0.572215 -0.760836 -0.951104  ...  0.955362 -0.796596 -0.321077 -0.624594   \n",
      "3 -0.674949 -1.169790 -1.180530  ... -1.440580 -1.018979 -0.176755 -1.040349   \n",
      "4 -0.713384 -1.195898 -1.169701  ... -2.541416 -1.099296 -0.211296 -1.176951   \n",
      "\n",
      "      Ch152     Ch154     Ch164     Ch166     Ch170     Ch172  \n",
      "0  0.094454  0.077129 -0.130081 -0.151594  0.308469 -0.080661  \n",
      "1 -0.260653 -0.494385  0.581731 -0.455110 -0.604185 -0.758347  \n",
      "2 -0.816367 -1.160003  1.032973 -0.349024 -1.084251 -1.186320  \n",
      "3 -1.135222 -1.505794 -0.350285 -0.000197 -1.118971 -1.409398  \n",
      "4 -1.254107 -1.653109 -0.546077  2.316686 -1.061013 -1.484535  \n",
      "\n",
      "[5 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "for sub in demographics:\n",
    "    data[sub] = data[sub].loc[:, hbr['channel']]\n",
    "\n",
    "print(data['P07'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2c: Load Workload File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>participant_number</th>\n",
       "      <th>trial</th>\n",
       "      <th>condition</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>extrinsic_load</th>\n",
       "      <th>intrinsic_load</th>\n",
       "      <th>condition_factor</th>\n",
       "      <th>last_trial</th>\n",
       "      <th>trial_clipped</th>\n",
       "      <th>response</th>\n",
       "      <th>pred_prob</th>\n",
       "      <th>pred_side</th>\n",
       "      <th>load_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17:06:55</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.842584</td>\n",
       "      <td>right</td>\n",
       "      <td>optimal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17:07:01</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.842584</td>\n",
       "      <td>right</td>\n",
       "      <td>optimal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17:07:13</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.842584</td>\n",
       "      <td>right</td>\n",
       "      <td>optimal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17:07:22</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.842584</td>\n",
       "      <td>right</td>\n",
       "      <td>overload</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17:07:29</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.842584</td>\n",
       "      <td>right</td>\n",
       "      <td>optimal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp  participant_number  trial condition  accuracy  extrinsic_load  \\\n",
       "0  17:06:55                   7      1        A3         1               0   \n",
       "1  17:07:01                   7      1        A3         1               0   \n",
       "2  17:07:13                   7      1        A3         1               0   \n",
       "3  17:07:22                   7      1        A3         0               0   \n",
       "4  17:07:29                   7      1        A3         1               0   \n",
       "\n",
       "   intrinsic_load condition_factor  last_trial  trial_clipped  response  \\\n",
       "0               1               A3           0              1         1   \n",
       "1               1               A3           0              1         1   \n",
       "2               1               A3           0              1         1   \n",
       "3               1               A3           0              1         0   \n",
       "4               1               A3           0              1         1   \n",
       "\n",
       "   pred_prob pred_side load_label  \n",
       "0   0.842584     right    optimal  \n",
       "1   0.842584     right    optimal  \n",
       "2   0.842584     right    optimal  \n",
       "3   0.842584     right   overload  \n",
       "4   0.842584     right    optimal  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the workload labels\n",
    "workload = pd.read_csv(\"data/load/workload.csv\")\n",
    "workload['timestamp'] = workload['timestamp'].str.replace('.', ':')\n",
    "\n",
    "workload.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>participant_number</th>\n",
       "      <th>trial</th>\n",
       "      <th>condition</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>extrinsic_load</th>\n",
       "      <th>intrinsic_load</th>\n",
       "      <th>condition_factor</th>\n",
       "      <th>last_trial</th>\n",
       "      <th>trial_clipped</th>\n",
       "      <th>response</th>\n",
       "      <th>pred_prob</th>\n",
       "      <th>pred_side</th>\n",
       "      <th>load_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17:06:55</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.842584</td>\n",
       "      <td>right</td>\n",
       "      <td>optimal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17:07:01</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.842584</td>\n",
       "      <td>right</td>\n",
       "      <td>optimal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17:07:13</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.842584</td>\n",
       "      <td>right</td>\n",
       "      <td>optimal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17:07:22</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.842584</td>\n",
       "      <td>right</td>\n",
       "      <td>overload</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17:07:29</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.842584</td>\n",
       "      <td>right</td>\n",
       "      <td>optimal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>17:36:12</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>S2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533406</td>\n",
       "      <td>right</td>\n",
       "      <td>overload</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>17:36:41</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>S2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533406</td>\n",
       "      <td>right</td>\n",
       "      <td>overload</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>17:36:48</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>S2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533406</td>\n",
       "      <td>right</td>\n",
       "      <td>overload</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>17:36:52</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>S2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533406</td>\n",
       "      <td>right</td>\n",
       "      <td>overload</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>17:36:54</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>S2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533406</td>\n",
       "      <td>right</td>\n",
       "      <td>overload</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp  participant_number  trial condition  accuracy  extrinsic_load  \\\n",
       "0    17:06:55                   7      1        A3         1               0   \n",
       "1    17:07:01                   7      1        A3         1               0   \n",
       "2    17:07:13                   7      1        A3         1               0   \n",
       "3    17:07:22                   7      1        A3         0               0   \n",
       "4    17:07:29                   7      1        A3         1               0   \n",
       "..        ...                 ...    ...       ...       ...             ...   \n",
       "157  17:36:12                   7      7        S2         0               1   \n",
       "158  17:36:41                   7      7        S2         0               1   \n",
       "159  17:36:48                   7      7        S2         0               1   \n",
       "160  17:36:52                   7      7        S2         0               1   \n",
       "161  17:36:54                   7      7        S2         0               1   \n",
       "\n",
       "     intrinsic_load condition_factor  last_trial  trial_clipped  response  \\\n",
       "0                 1               A3           0              1         1   \n",
       "1                 1               A3           0              1         1   \n",
       "2                 1               A3           0              1         1   \n",
       "3                 1               A3           0              1         0   \n",
       "4                 1               A3           0              1         1   \n",
       "..              ...              ...         ...            ...       ...   \n",
       "157               0               S2           1              6         0   \n",
       "158               0               S2           1              6         0   \n",
       "159               0               S2           1              6         0   \n",
       "160               0               S2           1              6         0   \n",
       "161               0               S2           1              6         0   \n",
       "\n",
       "     pred_prob pred_side load_label  \n",
       "0     0.842584     right    optimal  \n",
       "1     0.842584     right    optimal  \n",
       "2     0.842584     right    optimal  \n",
       "3     0.842584     right   overload  \n",
       "4     0.842584     right    optimal  \n",
       "..         ...       ...        ...  \n",
       "157   0.533406     right   overload  \n",
       "158   0.533406     right   overload  \n",
       "159   0.533406     right   overload  \n",
       "160   0.533406     right   overload  \n",
       "161   0.533406     right   overload  \n",
       "\n",
       "[162 rows x 14 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#separate the data into the different participants\n",
    "workload_dict = {}\n",
    "for i in range(len(demographics)):\n",
    "    workload_dict[demographics[i]] = workload[workload['participant_number'] == int(demographics[i][1:])].iloc[:, :]\n",
    "    workload_dict['P07']\n",
    "workload_dict['P07']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3020, 80)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(80,)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P07 = data['P07']\n",
    "onsets = timings[0]\n",
    "print(P07.shape)\n",
    "sample = onsets.iloc[0, 1]\n",
    "fnirs_sample = P07.iloc[sample,:]\n",
    "fnirs_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "23\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "print(len(timings))\n",
    "print(len(data))\n",
    "print(len(demographics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7  1 15 16 17 18 23 24 25]\n"
     ]
    }
   ],
   "source": [
    "unique_participant_numbers = workload['participant_number'].unique()\n",
    "print(unique_participant_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use to convert to the 1Hz sampling rate of the fnirs data\n",
    "sampling_rate = 3.8147\n",
    "def get_onset_index(timing, sampling_rate):\n",
    "    timing = timing / sampling_rate\n",
    "    return int(timing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Filter LSL --> Align Workload Timestamps with LSL Timestamps --> Output is Combined Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>participant_number</th>\n",
       "      <th>trial</th>\n",
       "      <th>condition</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>extrinsic_load</th>\n",
       "      <th>intrinsic_load</th>\n",
       "      <th>condition_factor</th>\n",
       "      <th>last_trial</th>\n",
       "      <th>trial_clipped</th>\n",
       "      <th>response</th>\n",
       "      <th>pred_prob</th>\n",
       "      <th>pred_side</th>\n",
       "      <th>load_label</th>\n",
       "      <th>time</th>\n",
       "      <th>onset</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17:06:55</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.842584</td>\n",
       "      <td>right</td>\n",
       "      <td>optimal</td>\n",
       "      <td>17:06:55</td>\n",
       "      <td>4533</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17:07:01</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.842584</td>\n",
       "      <td>right</td>\n",
       "      <td>optimal</td>\n",
       "      <td>17:07:01</td>\n",
       "      <td>4556</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17:07:13</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.842584</td>\n",
       "      <td>right</td>\n",
       "      <td>optimal</td>\n",
       "      <td>17:07:13</td>\n",
       "      <td>4600</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17:07:22</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.842584</td>\n",
       "      <td>right</td>\n",
       "      <td>overload</td>\n",
       "      <td>17:07:22</td>\n",
       "      <td>4634</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17:07:29</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.842584</td>\n",
       "      <td>right</td>\n",
       "      <td>optimal</td>\n",
       "      <td>17:07:29</td>\n",
       "      <td>4661</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp  participant_number  trial condition  accuracy  extrinsic_load  \\\n",
       "0  17:06:55                   7      1        A3         1               0   \n",
       "1  17:07:01                   7      1        A3         1               0   \n",
       "2  17:07:13                   7      1        A3         1               0   \n",
       "3  17:07:22                   7      1        A3         0               0   \n",
       "4  17:07:29                   7      1        A3         1               0   \n",
       "\n",
       "   intrinsic_load condition_factor  last_trial  trial_clipped  response  \\\n",
       "0               1               A3           0              1         1   \n",
       "1               1               A3           0              1         1   \n",
       "2               1               A3           0              1         1   \n",
       "3               1               A3           0              1         0   \n",
       "4               1               A3           0              1         1   \n",
       "\n",
       "   pred_prob pred_side load_label      time  onset  code  \n",
       "0   0.842584     right    optimal  17:06:55   4533   103  \n",
       "1   0.842584     right    optimal  17:07:01   4556    53  \n",
       "2   0.842584     right    optimal  17:07:13   4600   153  \n",
       "3   0.842584     right   overload  17:07:22   4634   163  \n",
       "4   0.842584     right    optimal  17:07:29   4661   153  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter matched_df to get rows where the timestamp is in the 'time' column of the first DataFrame in timings\n",
    "for i in range(len(demographics)):\n",
    "    matched_times = timings[i][timings[i]['time'].isin(workload_dict[demographics[i]]['timestamp'])]\n",
    "    workload_dict[demographics[i]] = workload_dict[demographics[i]].merge(matched_times, left_on='timestamp', right_on='time', how='left')\n",
    "workload_dict['P07'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1356, 320)\n",
      "(178, 320)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "#parameters \n",
    "window_size = 4\n",
    "#collating data and labels\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "groups = []\n",
    "\n",
    "#iterate through the subjects\n",
    "for sub in demographics:\n",
    "    num_samples = 0\n",
    "    sub_metadata = workload_dict[sub]\n",
    "    sub_data = data[sub].to_numpy()\n",
    "    for row in sub_metadata.itertuples():\n",
    "        onset = row.onset\n",
    "        label = row.load_label\n",
    "\n",
    "        #Get the corresponding fnirs sample \n",
    "        index = get_onset_index(onset, sampling_rate)\n",
    "        \n",
    "        #Calculate the window and flatten to be compatible with the model\n",
    "        fnirs_sample = sub_data[index-window_size+1:index+1].flatten()\n",
    "\n",
    "        if np.isnan(fnirs_sample).any():\n",
    "            continue\n",
    "        \n",
    "        X.append(fnirs_sample)\n",
    "        y.append(label)\n",
    "        groups.append(sub)\n",
    "    \n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "#split into groups based on participants to ensure no crossover between train and test sets\n",
    "groups = np.array(groups)\n",
    "group_kfold = GroupKFold(n_splits=len(np.unique(groups)))\n",
    "group_kfold.get_n_splits(X, y, groups)\n",
    "#split into train and test\n",
    "for train_index, test_index in group_kfold.split(X, y, groups):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change from labels to ints\n",
    "y_train = [0 if i == 'optimal' else 1 for i in y_train]\n",
    "y_test = [0 if i == 'optimal' else 1 for i in y_test]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1356, 320)\n",
      "(178, 320)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import svm\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.utils import shuffle\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# # I wanted to try some features from my old assignment models (1/2)\n",
    "# X_train, y_train = shuffle(X_train, y_train, random_state =1)\n",
    "# X_test, y_test = shuffle(X_test, y_test, random_state=1)\n",
    "\n",
    "# # Specific participants are being separated above\n",
    "# # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html\n",
    "# sm = SMOTE(random_state=42)\n",
    "# X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# # Should we standardize? Yes but only for SVM and not RF?\n",
    "# # https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "# # scaler = StandardScaler()\n",
    "# # X_train = scaler.fit_transform(X_train)\n",
    "# # X_test = scaler.transform(X_test)\n",
    "\n",
    "# # I wanted to try some features from my old assignment models (2/2)\n",
    "# # Run only a subset to find the optimal hyperparameters\n",
    "# # subset_size = int(0.3 * X_train.shape[0])\n",
    "# # X_train = X_train[:subset_size]\n",
    "# # y_train = y_train[:subset_size]\n",
    "# # # subset_size = int(0.3 * X_test.shape[0])\n",
    "# # X_test = X_test[:subset_size]\n",
    "# # y_test = y_test[:subset_size]\n",
    "# # Define parameter options\n",
    "# parameters = [{'C': [1, 10], 'gamma': [0.1, 1, 'scale'], 'kernel': ['rbf', 'linear']},]\n",
    "# # KFold\n",
    "# cv = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "# # GridSearch to find best hyperparameters\n",
    "# clf = GridSearchCV(SVC(class_weight='balanced'), param_grid=parameters, scoring='accuracy', cv=cv)\n",
    "\n",
    "# # I tested out RF temporarily and it performed worse (at time of code - status may change)\n",
    "# # https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "# # clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "\n",
    "# # clf = svm.SVC()\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Best hyperparameters: \", clf.best_params_)\n",
    "\n",
    "# y_train_pred = clf.predict(X_train)\n",
    "\n",
    "# print(\"Training Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "\n",
    "\n",
    "# y_pred = clf.predict(X_test)\n",
    "# print(y_pred)\n",
    "\n",
    "# print(\"Testing Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.7865168539325843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       154\n",
      "           1       0.11      0.08      0.10        24\n",
      "\n",
      "    accuracy                           0.79       178\n",
      "   macro avg       0.49      0.49      0.49       178\n",
      "weighted avg       0.76      0.79      0.77       178\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# ros = RandomOverSampler(random_state=42)\n",
    "# X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workload",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
