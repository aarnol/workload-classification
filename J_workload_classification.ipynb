{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0adcb7f5-898d-4000-a2cb-982ae45829d3",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32951ceb-c1f4-44b6-9e67-dbeaf5ae41d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.io as sio\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc82803c-0a86-4cb1-9f93-d19e2d14bcf2",
   "metadata": {},
   "source": [
    "# Load .MAT --> Jk Load .CSV (s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b30b6c-934a-4071-8efe-bbabbce24680",
   "metadata": {},
   "source": [
    "### Ok information overload here:\n",
    "#### TLDR: .mat contains fNIRS data saved as nirs.core.Data now saved as CSV files\n",
    "#### * Download nirs-toolbox (https://github.com/huppertt/nirs-toolbox/releases/tag/v2022.4.26) and save to documents/matlab/toolboxes\n",
    "#### * Matlab < Home < Set Path < Add with subdirectories < documents/matlab/toolboxes/nirs-toolbox\n",
    "#### * load('Data_fNIRS_Clean_23.mat') provides a demographics table and a nirs.core.Data \"table\" for lack of a better comparison\n",
    "#### * I rather just export the data differently (as CSV files) prior to working with them in Python\n",
    "#### * New CSV files are included in the github push in the 'data_csvs' folder\n",
    "#### * This was such a pain but accomplished!! Saved as 'export_hb_filt_to_csv.m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3395ffea-1a9d-44de-b3aa-543538cc5382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As Alex found out, the .mat file contains a table or other Matlab class object\n",
    "# SciPy cannot directly parse this custom class\n",
    "\n",
    "# mat_data = scipy.io.loadmat('Data_fNIRS_Clean_23')\n",
    "# print(mat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f8298c9-3fd8-47b7-a917-298471a31cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I couldn't seem to get a struct though - no struct object to pull from\n",
    "\n",
    "# data = sio.loadmat(\n",
    "#     'Data_fNIRS_Clean_23.mat', \n",
    "#     struct_as_record=False, \n",
    "#     squeeze_me=True\n",
    "# )\n",
    "# print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f06cbaa2-3876-49a1-92b1-0bb45e960b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded participant IDs: dict_keys(['P07', 'P10', 'P11', 'P13', 'P14', 'P16', 'P17', 'P18', 'P22', 'P23', 'P24', 'P25', 'P26', 'P27', 'P28', 'P29', 'P30', 'P31', 'P32', 'P33', 'P34', 'P35', 'P36'])\n"
     ]
    }
   ],
   "source": [
    "# Define the directory containing the CSV files\n",
    "data_csvs = 'data_csvs'  # Change this path if your data is in a different directory\n",
    "\n",
    "# Use glob to find all CSV files in the directory\n",
    "csv_files = glob.glob(os.path.join(data_csvs, '*.csv'))\n",
    "\n",
    "# Initialize an empty dictionary to store data\n",
    "participants_data = {}\n",
    "\n",
    "# Iterate over each CSV file and load the data\n",
    "for file in csv_files:\n",
    "    # Extract the participant ID from the filename\n",
    "    # Assumes filename format is 'P07.csv', 'P12.csv', etc.\n",
    "    participant_id = os.path.splitext(os.path.basename(file))[0]\n",
    "    \n",
    "    # Read the CSV into a pandas DataFrame\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Optional: Add a column for participant ID\n",
    "    df['Participant_ID'] = participant_id\n",
    "    \n",
    "    # Store the DataFrame in the dictionary\n",
    "    participants_data[participant_id] = df\n",
    "\n",
    "# Optional: Display the keys (participant IDs) to verify\n",
    "print(\"Loaded participant IDs:\", participants_data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79014670-d05f-40c9-a6db-ec012491ac94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Time        Ch1       Ch2        Ch3       Ch4        Ch5       Ch6  \\\n",
      "0  0.000000 -30.737259  4.217945  -9.949267  7.276555 -25.171749  0.132245   \n",
      "1  0.262144 -29.338383  4.719302 -12.477225  6.479262 -25.561359 -0.462352   \n",
      "2  0.524288 -27.876869  5.192062 -14.931240  5.624817 -25.899460 -0.941451   \n",
      "3  0.786432 -26.310300  5.614543 -17.221782  4.683419 -26.157453 -1.199534   \n",
      "4  1.048576 -24.616998  5.967590 -19.276144  3.636096 -26.324703 -1.152255   \n",
      "\n",
      "        Ch7       Ch8        Ch9  ...     Ch170      Ch171      Ch172  \\\n",
      "0 -6.699986  3.965802 -38.122370  ... -6.985181 -11.016354  -2.944079   \n",
      "1 -4.677611  3.911549 -34.141558  ... -3.168199  -5.667243   1.034301   \n",
      "2 -2.413918  3.984652 -30.318783  ...  0.555269  -0.175635   5.158467   \n",
      "3  0.300224  4.304991 -26.864080  ...  4.050139   5.529127   9.518427   \n",
      "4  3.624535  4.968803 -23.961938  ...  7.182750  11.466906  14.158541   \n",
      "\n",
      "         Ch173       Ch174      Ch175      Ch176       Ch177       Ch178  \\\n",
      "0 -1915.916365  992.854127  68.010023 -94.658397  -26.975538 -165.363934   \n",
      "1 -1908.717287  739.589217  59.892367 -77.957573   43.041697 -251.380385   \n",
      "2 -1895.673217  499.820467  52.134970 -61.983833  109.585165 -331.953735   \n",
      "3 -1877.150443  288.556945  44.999658 -47.697218  169.313541 -402.179494   \n",
      "4 -1857.126648  119.693401  38.618282 -35.829834  219.737988 -458.387361   \n",
      "\n",
      "   Participant_ID  \n",
      "0             P07  \n",
      "1             P07  \n",
      "2             P07  \n",
      "3             P07  \n",
      "4             P07  \n",
      "\n",
      "[5 rows x 180 columns]\n"
     ]
    }
   ],
   "source": [
    "# Access DataFrame for participant 'P07'\n",
    "p07_data = participants_data['P07']\n",
    "\n",
    "# Display the first five rows of P07's data\n",
    "print(p07_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600491f3-9109-4749-81b6-33f73ed23e6b",
   "metadata": {},
   "source": [
    "# The Fun Part! Bring in the LSL.tri Files = Dividing the data into conditions & eventually errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4e4e77-5ba8-44e4-97e0-fb90dd48c7ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
